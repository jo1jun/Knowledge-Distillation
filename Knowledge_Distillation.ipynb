{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Knowledge_Distillation.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "mount_file_id": "1YcFV-da6HR3CNk_8n9KUbA_ieGm75iEa",
      "authorship_tag": "ABX9TyPuUGvf0A8jDw87v1iDJm/s",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "88cfbd2161724566a34fea230094b4b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_c3b1c18b8cee4d51b7f434f459321e10",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_2a7858598fcd471f97de4e759a5bfb5a",
              "IPY_MODEL_ec65b326467344a68b78cf249daa44a8",
              "IPY_MODEL_1ac6d203e24f40a8a8f8f2395adcc18f"
            ]
          }
        },
        "c3b1c18b8cee4d51b7f434f459321e10": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2a7858598fcd471f97de4e759a5bfb5a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_ec9165231cb74b8eb8f15ab0fc016a21",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_eb76ebeaeb5a47e981b53cf21d0defa4"
          }
        },
        "ec65b326467344a68b78cf249daa44a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_85bb889387ce477c939d95e3646cc3b3",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 170498071,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 170498071,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_71da9b093faf45439af202932577dcae"
          }
        },
        "1ac6d203e24f40a8a8f8f2395adcc18f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_b0063e42758d41a99b42123d5596e528",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 170499072/? [00:03&lt;00:00, 46921319.63it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0312c972a2964fb09e6d9e3f7df6c511"
          }
        },
        "ec9165231cb74b8eb8f15ab0fc016a21": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "eb76ebeaeb5a47e981b53cf21d0defa4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "85bb889387ce477c939d95e3646cc3b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "71da9b093faf45439af202932577dcae": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b0063e42758d41a99b42123d5596e528": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0312c972a2964fb09e6d9e3f7df6c511": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jo1jun/Knowledge-Distillation/blob/main/Knowledge_Distillation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AoAg2WbV5hP5"
      },
      "source": [
        "# Import"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OdgCXuhb5gm9"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import sampler\n",
        "\n",
        "import torchvision.datasets as dset\n",
        "import torchvision.transforms as T\n",
        "\n",
        "import numpy as np\n",
        "import copy\n",
        "\n",
        "# tensorboard writer\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FWY4iuIO6Dfc"
      },
      "source": [
        "# Classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WjefvTSj5loj"
      },
      "source": [
        "## CIFAR10 Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119,
          "referenced_widgets": [
            "88cfbd2161724566a34fea230094b4b8",
            "c3b1c18b8cee4d51b7f434f459321e10",
            "2a7858598fcd471f97de4e759a5bfb5a",
            "ec65b326467344a68b78cf249daa44a8",
            "1ac6d203e24f40a8a8f8f2395adcc18f",
            "ec9165231cb74b8eb8f15ab0fc016a21",
            "eb76ebeaeb5a47e981b53cf21d0defa4",
            "85bb889387ce477c939d95e3646cc3b3",
            "71da9b093faf45439af202932577dcae",
            "b0063e42758d41a99b42123d5596e528",
            "0312c972a2964fb09e6d9e3f7df6c511"
          ]
        },
        "id": "p2mPtZzy5pFZ",
        "outputId": "14c9ced7-1b16-412f-ff51-e1585136a235"
      },
      "source": [
        "NUM_TRAIN = 49000\n",
        "\n",
        "transform = T.Compose([\n",
        "                T.ToTensor(),\n",
        "                T.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
        "            ])\n",
        "\n",
        "dataloaders = {}\n",
        "\n",
        "cifar10_train = dset.CIFAR10('./datasets', train=True, download=True,\n",
        "                             transform=transform)\n",
        "dataloaders['train'] = DataLoader(cifar10_train, batch_size=64, \n",
        "                          sampler=sampler.SubsetRandomSampler(range(NUM_TRAIN)))\n",
        "\n",
        "cifar10_val = dset.CIFAR10('./datasets', train=True, download=True,\n",
        "                           transform=transform)\n",
        "dataloaders['val'] = DataLoader(cifar10_val, batch_size=64, \n",
        "                        sampler=sampler.SubsetRandomSampler(range(NUM_TRAIN, 50000)))\n",
        "\n",
        "cifar10_test = dset.CIFAR10('./datasets', train=False, download=True, \n",
        "                            transform=transform)\n",
        "dataloaders['test'] = DataLoader(cifar10_test, batch_size=64)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./datasets/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "88cfbd2161724566a34fea230094b4b8",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/170498071 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./datasets/cifar-10-python.tar.gz to ./datasets\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vdcN8xvm8RjU"
      },
      "source": [
        "## Trainer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Vo3LJ708S7p"
      },
      "source": [
        "def trainer(model_name, model, criterion, optimizer, num_epochs):\n",
        "\n",
        "    model.to(device)\n",
        "    writer = SummaryWriter(f'runs/{model_name}')\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    global_step, best_acc = 0, 0.0\n",
        "    running_loss, running_acc = {}, {}\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
        "        print('-' * 10)\n",
        "\n",
        "        # Each epoch has a training and validation phase\n",
        "        for phase in ['train', 'val']:\n",
        "            if phase == 'train':\n",
        "                model.train()  # Set model to training mode\n",
        "            else:\n",
        "                model.eval()   # Set model to evaluate mode\n",
        "\n",
        "            running_loss[phase], running_acc[phase] = 0.0, 0\n",
        "\n",
        "            # Iterate over data.\n",
        "            for inputs, labels in dataloaders[phase]:\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                # zero the parameter gradients\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # forward\n",
        "                # track history if only in train\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    outputs = model(inputs)\n",
        "                    _, preds = torch.max(outputs, 1)\n",
        "                    loss = criterion(outputs, labels)\n",
        "\n",
        "                    # backward + optimize only if in training phase\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "                # statistics\n",
        "                running_loss[phase] += loss.item() * inputs.shape[0]\n",
        "                running_acc[phase] += torch.sum(preds == labels.data)\n",
        "            \n",
        "            running_loss[phase] = running_loss[phase] / (len(dataloaders[phase]) * dataloaders[phase].batch_size)\n",
        "            running_acc[phase] = running_acc[phase].double() / (len(dataloaders[phase]) * dataloaders[phase].batch_size)\n",
        "\n",
        "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, running_loss[phase], running_acc[phase]))\n",
        "\n",
        "            # deep copy the model\n",
        "            if phase == 'val' and running_acc[phase] > best_acc:\n",
        "                best_acc = running_acc[phase]\n",
        "                best_model_wts = copy.deepcopy(model.state_dict())\n",
        "\n",
        "        writer.add_scalars(f'{model_name}/loss', {'train' : running_loss['train'], 'val' : running_loss['val']}, global_step)\n",
        "        writer.add_scalars(f'{model_name}/acc', {'train' : running_acc['train'], 'val' : running_acc['val']}, global_step)\n",
        "        global_step += 1\n",
        "\n",
        "        print()\n",
        "\n",
        "    print('Best val Acc: {:4f}'.format(best_acc))\n",
        "\n",
        "    # load best model weights\n",
        "    model.load_state_dict(best_model_wts)\n",
        "\n",
        "    torch.save(model.state_dict(), f'{model_name}.pt')\n",
        "    print('model saved')\n",
        "\n",
        "    writer.close()\n",
        "\n",
        "    return model"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hzhd3M2P6FYE"
      },
      "source": [
        "## Teacher"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JOJpOKdL6Go0"
      },
      "source": [
        "class Teacher(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=2, padding=1)\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
        "        self.conv3 = nn.Conv2d(64, 128, kernel_size=5, padding=1)\n",
        "        self.conv4 = nn.Conv2d(128, 64, kernel_size=5, stride=2, padding=1)\n",
        "        self.conv5 = nn.Conv2d(64, 10, kernel_size=3, stride=2, padding=1)\n",
        "        self.batch1 = nn.BatchNorm2d(32)\n",
        "        self.batch2 = nn.BatchNorm2d(64)\n",
        "        self.batch3 = nn.BatchNorm2d(128)\n",
        "        self.batch4 = nn.BatchNorm2d(64)\n",
        "        self.batch5 = nn.BatchNorm2d(10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.batch1(self.conv1(x)))\n",
        "        x = F.dropout2d(F.relu(self.batch2(self.conv2(x))), 0.1)\n",
        "        x = F.dropout2d(F.relu(self.batch3(self.conv3(x))), 0.2)\n",
        "        x = F.dropout2d(F.relu(self.batch4(self.conv4(x))), 0.1)\n",
        "        x = F.relu(self.batch5(self.conv5(x)))\n",
        "        x = F.avg_pool2d(x, x.shape[-2:]).squeeze() # global average pooling\n",
        "        return x"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e6SEfMGj8pBE",
        "outputId": "8bbf6d8c-85fd-40c8-edf4-b0ed4083e6ad"
      },
      "source": [
        "teacher = Teacher()\n",
        "print(sum(p.numel() for p in teacher.parameters() if p.requires_grad))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "435550\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5qm4cDGnDhlD"
      },
      "source": [
        "## Criterion"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6oKi9l_fDjOT"
      },
      "source": [
        "criterion = nn.CrossEntropyLoss()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dg-vEYSY82Ik"
      },
      "source": [
        "## Teacher Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MMfVuQX28uZ8",
        "outputId": "326e2e8c-56b5-451d-cd93-7cfc100b0aff"
      },
      "source": [
        "optimizer = optim.Adam(teacher.parameters())\n",
        "best_teacher = trainer('teacher', teacher, criterion, optimizer, num_epochs=30)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0/29\n",
            "----------\n",
            "train Loss: 1.6532 Acc: 0.4441\n",
            "val Loss: 1.4195 Acc: 0.5020\n",
            "\n",
            "Epoch 1/29\n",
            "----------\n",
            "train Loss: 1.2918 Acc: 0.5753\n",
            "val Loss: 1.1318 Acc: 0.5938\n",
            "\n",
            "Epoch 2/29\n",
            "----------\n",
            "train Loss: 1.1036 Acc: 0.6380\n",
            "val Loss: 1.0195 Acc: 0.6455\n",
            "\n",
            "Epoch 3/29\n",
            "----------\n",
            "train Loss: 0.9818 Acc: 0.6767\n",
            "val Loss: 0.8811 Acc: 0.6777\n",
            "\n",
            "Epoch 4/29\n",
            "----------\n",
            "train Loss: 0.8873 Acc: 0.7060\n",
            "val Loss: 0.9025 Acc: 0.6982\n",
            "\n",
            "Epoch 5/29\n",
            "----------\n",
            "train Loss: 0.8117 Acc: 0.7324\n",
            "val Loss: 0.8130 Acc: 0.7100\n",
            "\n",
            "Epoch 6/29\n",
            "----------\n",
            "train Loss: 0.7472 Acc: 0.7537\n",
            "val Loss: 0.7665 Acc: 0.7275\n",
            "\n",
            "Epoch 7/29\n",
            "----------\n",
            "train Loss: 0.6957 Acc: 0.7696\n",
            "val Loss: 0.7533 Acc: 0.7207\n",
            "\n",
            "Epoch 8/29\n",
            "----------\n",
            "train Loss: 0.6446 Acc: 0.7875\n",
            "val Loss: 0.7445 Acc: 0.7295\n",
            "\n",
            "Epoch 9/29\n",
            "----------\n",
            "train Loss: 0.5976 Acc: 0.8041\n",
            "val Loss: 0.7441 Acc: 0.7256\n",
            "\n",
            "Epoch 10/29\n",
            "----------\n",
            "train Loss: 0.5565 Acc: 0.8169\n",
            "val Loss: 0.7384 Acc: 0.7461\n",
            "\n",
            "Epoch 11/29\n",
            "----------\n",
            "train Loss: 0.5167 Acc: 0.8308\n",
            "val Loss: 0.7614 Acc: 0.7246\n",
            "\n",
            "Epoch 12/29\n",
            "----------\n",
            "train Loss: 0.4839 Acc: 0.8425\n",
            "val Loss: 0.7561 Acc: 0.7354\n",
            "\n",
            "Epoch 13/29\n",
            "----------\n",
            "train Loss: 0.4486 Acc: 0.8548\n",
            "val Loss: 0.8212 Acc: 0.7051\n",
            "\n",
            "Epoch 14/29\n",
            "----------\n",
            "train Loss: 0.4199 Acc: 0.8635\n",
            "val Loss: 0.7987 Acc: 0.7158\n",
            "\n",
            "Epoch 15/29\n",
            "----------\n",
            "train Loss: 0.3974 Acc: 0.8725\n",
            "val Loss: 0.8154 Acc: 0.7119\n",
            "\n",
            "Epoch 16/29\n",
            "----------\n",
            "train Loss: 0.3646 Acc: 0.8837\n",
            "val Loss: 0.8052 Acc: 0.7139\n",
            "\n",
            "Epoch 17/29\n",
            "----------\n",
            "train Loss: 0.3496 Acc: 0.8853\n",
            "val Loss: 0.8264 Acc: 0.7158\n",
            "\n",
            "Epoch 18/29\n",
            "----------\n",
            "train Loss: 0.3248 Acc: 0.8942\n",
            "val Loss: 0.8741 Acc: 0.7021\n",
            "\n",
            "Epoch 19/29\n",
            "----------\n",
            "train Loss: 0.3077 Acc: 0.9008\n",
            "val Loss: 0.8614 Acc: 0.7090\n",
            "\n",
            "Epoch 20/29\n",
            "----------\n",
            "train Loss: 0.2964 Acc: 0.9048\n",
            "val Loss: 0.9244 Acc: 0.6865\n",
            "\n",
            "Epoch 21/29\n",
            "----------\n",
            "train Loss: 0.2789 Acc: 0.9103\n",
            "val Loss: 0.8980 Acc: 0.7002\n",
            "\n",
            "Epoch 22/29\n",
            "----------\n",
            "train Loss: 0.2655 Acc: 0.9146\n",
            "val Loss: 0.8321 Acc: 0.7080\n",
            "\n",
            "Epoch 23/29\n",
            "----------\n",
            "train Loss: 0.2573 Acc: 0.9170\n",
            "val Loss: 0.8607 Acc: 0.7197\n",
            "\n",
            "Epoch 24/29\n",
            "----------\n",
            "train Loss: 0.2473 Acc: 0.9190\n",
            "val Loss: 0.9214 Acc: 0.6982\n",
            "\n",
            "Epoch 25/29\n",
            "----------\n",
            "train Loss: 0.2458 Acc: 0.9186\n",
            "val Loss: 0.8925 Acc: 0.7070\n",
            "\n",
            "Epoch 26/29\n",
            "----------\n",
            "train Loss: 0.2341 Acc: 0.9246\n",
            "val Loss: 0.9466 Acc: 0.6982\n",
            "\n",
            "Epoch 27/29\n",
            "----------\n",
            "train Loss: 0.2209 Acc: 0.9286\n",
            "val Loss: 0.9235 Acc: 0.6914\n",
            "\n",
            "Epoch 28/29\n",
            "----------\n",
            "train Loss: 0.2157 Acc: 0.9301\n",
            "val Loss: 0.9627 Acc: 0.7178\n",
            "\n",
            "Epoch 29/29\n",
            "----------\n",
            "train Loss: 0.2101 Acc: 0.9321\n",
            "val Loss: 0.9751 Acc: 0.6943\n",
            "\n",
            "Best val Acc: 0.746094\n",
            "model saved\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x_t--f4b9rIQ"
      },
      "source": [
        "## Checker"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SUge9itC9t_8"
      },
      "source": [
        "def checker(loader, model):\n",
        "    num_correct = 0\n",
        "    num_samples = 0\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for x, y in loader:\n",
        "            x = x.to(device=device)\n",
        "            y = y.to(device=device)\n",
        "            scores = model(x)\n",
        "            _, preds = scores.max(1)\n",
        "            num_correct += (preds == y).sum()\n",
        "            num_samples += preds.size(0)\n",
        "        acc = float(num_correct) / num_samples\n",
        "        print('Got %d / %d correct (%.2f)' % (num_correct, num_samples, 100 * acc))"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fEiqIHZ-_Uqo"
      },
      "source": [
        "## Teacher Accuracy Check"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vz-MC7Qr99-s",
        "outputId": "b67fa9be-6e23-4c76-9e6e-3c063d47c649"
      },
      "source": [
        "checker(dataloaders['test'], best_teacher)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Got 7413 / 10000 correct (74.13)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yOJZKKDs-cxY"
      },
      "source": [
        "## Student_Solo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CwYZEDn6-ipy"
      },
      "source": [
        "class Student_Solo(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=2, padding=1)\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
        "        self.conv3 = nn.Conv2d(64, 64, kernel_size=3, padding=1)\n",
        "        self.conv4 = nn.Conv2d(64, 10, kernel_size=3, stride=2, padding=1)\n",
        "        self.batch1 = nn.BatchNorm2d(32)\n",
        "        self.batch2 = nn.BatchNorm2d(64)\n",
        "        self.batch3 = nn.BatchNorm2d(64)\n",
        "        self.batch4 = nn.BatchNorm2d(10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.batch1(self.conv1(x)))\n",
        "        x = F.dropout2d(F.relu(self.batch2(self.conv2(x))), 0.1)\n",
        "        x = F.dropout2d(F.relu(self.batch3(self.conv3(x))), 0.1)\n",
        "        x = F.relu(self.batch4(self.conv4(x)))\n",
        "        x = F.avg_pool2d(x, x.shape[-2:]).squeeze() # global average pooling\n",
        "        return x"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "36tE-71__FrA",
        "outputId": "7ce58323-2784-4725-97c5-aacf0acb56d6"
      },
      "source": [
        "student_solo = Student_Solo()\n",
        "print(sum(p.numel() for p in student_solo.parameters() if p.requires_grad))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "62430\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p3XA1BXW_ARh"
      },
      "source": [
        "## Student_Solo Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FJPddHyB_COB",
        "outputId": "9228842a-5c13-435f-adb8-670a5524fcb1"
      },
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(student_solo.parameters())\n",
        "best_student_solo = trainer('student_solo', student_solo, criterion, optimizer, num_epochs=30)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0/29\n",
            "----------\n",
            "train Loss: 1.7864 Acc: 0.4005\n",
            "val Loss: 1.5566 Acc: 0.4463\n",
            "\n",
            "Epoch 1/29\n",
            "----------\n",
            "train Loss: 1.5227 Acc: 0.4974\n",
            "val Loss: 1.3899 Acc: 0.4961\n",
            "\n",
            "Epoch 2/29\n",
            "----------\n",
            "train Loss: 1.3723 Acc: 0.5480\n",
            "val Loss: 1.2770 Acc: 0.5557\n",
            "\n",
            "Epoch 3/29\n",
            "----------\n",
            "train Loss: 1.2643 Acc: 0.5807\n",
            "val Loss: 1.1855 Acc: 0.5781\n",
            "\n",
            "Epoch 4/29\n",
            "----------\n",
            "train Loss: 1.1856 Acc: 0.6088\n",
            "val Loss: 1.1161 Acc: 0.6016\n",
            "\n",
            "Epoch 5/29\n",
            "----------\n",
            "train Loss: 1.1215 Acc: 0.6280\n",
            "val Loss: 1.0756 Acc: 0.6221\n",
            "\n",
            "Epoch 6/29\n",
            "----------\n",
            "train Loss: 1.0736 Acc: 0.6415\n",
            "val Loss: 1.0237 Acc: 0.6377\n",
            "\n",
            "Epoch 7/29\n",
            "----------\n",
            "train Loss: 1.0314 Acc: 0.6539\n",
            "val Loss: 1.0258 Acc: 0.6318\n",
            "\n",
            "Epoch 8/29\n",
            "----------\n",
            "train Loss: 0.9936 Acc: 0.6678\n",
            "val Loss: 0.9561 Acc: 0.6650\n",
            "\n",
            "Epoch 9/29\n",
            "----------\n",
            "train Loss: 0.9615 Acc: 0.6787\n",
            "val Loss: 0.9354 Acc: 0.6504\n",
            "\n",
            "Epoch 10/29\n",
            "----------\n",
            "train Loss: 0.9341 Acc: 0.6883\n",
            "val Loss: 0.9291 Acc: 0.6582\n",
            "\n",
            "Epoch 11/29\n",
            "----------\n",
            "train Loss: 0.9061 Acc: 0.6974\n",
            "val Loss: 0.9249 Acc: 0.6543\n",
            "\n",
            "Epoch 12/29\n",
            "----------\n",
            "train Loss: 0.8802 Acc: 0.7039\n",
            "val Loss: 0.9198 Acc: 0.6689\n",
            "\n",
            "Epoch 13/29\n",
            "----------\n",
            "train Loss: 0.8598 Acc: 0.7136\n",
            "val Loss: 0.9051 Acc: 0.6650\n",
            "\n",
            "Epoch 14/29\n",
            "----------\n",
            "train Loss: 0.8394 Acc: 0.7181\n",
            "val Loss: 0.8766 Acc: 0.6797\n",
            "\n",
            "Epoch 15/29\n",
            "----------\n",
            "train Loss: 0.8231 Acc: 0.7266\n",
            "val Loss: 0.8729 Acc: 0.6689\n",
            "\n",
            "Epoch 16/29\n",
            "----------\n",
            "train Loss: 0.8037 Acc: 0.7324\n",
            "val Loss: 0.8569 Acc: 0.6807\n",
            "\n",
            "Epoch 17/29\n",
            "----------\n",
            "train Loss: 0.7872 Acc: 0.7378\n",
            "val Loss: 0.8813 Acc: 0.6768\n",
            "\n",
            "Epoch 18/29\n",
            "----------\n",
            "train Loss: 0.7716 Acc: 0.7408\n",
            "val Loss: 0.8797 Acc: 0.6719\n",
            "\n",
            "Epoch 19/29\n",
            "----------\n",
            "train Loss: 0.7599 Acc: 0.7463\n",
            "val Loss: 0.8564 Acc: 0.6758\n",
            "\n",
            "Epoch 20/29\n",
            "----------\n",
            "train Loss: 0.7444 Acc: 0.7508\n",
            "val Loss: 0.8774 Acc: 0.6650\n",
            "\n",
            "Epoch 21/29\n",
            "----------\n",
            "train Loss: 0.7316 Acc: 0.7585\n",
            "val Loss: 0.8731 Acc: 0.6934\n",
            "\n",
            "Epoch 22/29\n",
            "----------\n",
            "train Loss: 0.7213 Acc: 0.7602\n",
            "val Loss: 0.8464 Acc: 0.6855\n",
            "\n",
            "Epoch 23/29\n",
            "----------\n",
            "train Loss: 0.7102 Acc: 0.7623\n",
            "val Loss: 0.8327 Acc: 0.6777\n",
            "\n",
            "Epoch 24/29\n",
            "----------\n",
            "train Loss: 0.6962 Acc: 0.7672\n",
            "val Loss: 0.8197 Acc: 0.7002\n",
            "\n",
            "Epoch 25/29\n",
            "----------\n",
            "train Loss: 0.6904 Acc: 0.7671\n",
            "val Loss: 0.8391 Acc: 0.6934\n",
            "\n",
            "Epoch 26/29\n",
            "----------\n",
            "train Loss: 0.6810 Acc: 0.7717\n",
            "val Loss: 0.8636 Acc: 0.6631\n",
            "\n",
            "Epoch 27/29\n",
            "----------\n",
            "train Loss: 0.6693 Acc: 0.7755\n",
            "val Loss: 0.8532 Acc: 0.6963\n",
            "\n",
            "Epoch 28/29\n",
            "----------\n",
            "train Loss: 0.6642 Acc: 0.7777\n",
            "val Loss: 0.8544 Acc: 0.6816\n",
            "\n",
            "Epoch 29/29\n",
            "----------\n",
            "train Loss: 0.6522 Acc: 0.7804\n",
            "val Loss: 0.8405 Acc: 0.6982\n",
            "\n",
            "Best val Acc: 0.700195\n",
            "model saved\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KTo7Qfni_YrY"
      },
      "source": [
        "## Student_Solo Accuracy Check"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "snZil1Zr_a9Z",
        "outputId": "417f4ed3-4d56-4b55-9787-2691191dd4f9"
      },
      "source": [
        "checker(dataloaders['test'], best_student_solo)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Got 7022 / 10000 correct (70.22)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v9KYLLy-_dQB"
      },
      "source": [
        "## Student"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UPu-MJZ9AErk",
        "outputId": "9a233ea8-f690-4e93-d691-e0d98da1d11f"
      },
      "source": [
        "student = Student_Solo() # same architecture with student_solo\n",
        "print(sum(p.numel() for p in student_solo.parameters() if p.requires_grad))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "62430\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-6M6KccJDdZO"
      },
      "source": [
        "## Criterion (Distillation)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HJ61xe3cDgGT"
      },
      "source": [
        "def criterion_KD(outputs, labels, teacher_outputs, T, alpha):\n",
        "    \"\"\"\n",
        "    Compute the knowledge-distillation (KD) loss given outputs, labels.\n",
        "    \"Hyperparameters\": temperature and alpha\n",
        "    NOTE: the KL Divergence for PyTorch comparing the softmaxs of teacher\n",
        "    and student expects the input tensor to be log probabilities! See Issue #2\n",
        "    \"\"\"\n",
        "    KD_loss = nn.KLDivLoss()(F.log_softmax(outputs/T, dim=1),\n",
        "                             F.softmax(teacher_outputs/T, dim=1)) * (alpha * T * T) + \\\n",
        "              F.cross_entropy(outputs, labels) * (1. - alpha)\n",
        "\n",
        "    return KD_loss"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "se9yvCMvENYs"
      },
      "source": [
        "## Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oXvWcn3tEQzn"
      },
      "source": [
        "T = 10\n",
        "alpha = 0.5"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UDhpnZOSCOgB"
      },
      "source": [
        "## Trainer (+Distillation loss)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jvc24qWRCU2g"
      },
      "source": [
        "def trainer_KD(model_name, model, teacher, optimizer, num_epochs):\n",
        "\n",
        "    model.to(device)\n",
        "    teacher.to(device)\n",
        "    teacher.eval()\n",
        "    writer = SummaryWriter(f'runs/{model_name}')\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    global_step, best_acc = 0, 0.0\n",
        "    running_loss, running_acc = {}, {}\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
        "        print('-' * 10)\n",
        "\n",
        "        # Each epoch has a training and validation phase\n",
        "        for phase in ['train', 'val']:\n",
        "            if phase == 'train':\n",
        "                model.train()  # Set model to training mode\n",
        "            else:\n",
        "                model.eval()   # Set model to evaluate mode\n",
        "\n",
        "            running_loss[phase], running_acc[phase] = 0.0, 0\n",
        "\n",
        "            # Iterate over data.\n",
        "            for inputs, labels in dataloaders[phase]:\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                # zero the parameter gradients\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "\n",
        "                with torch.no_grad():\n",
        "                  outputs_teacher = teacher(inputs)\n",
        "\n",
        "                # forward\n",
        "                # track history if only in train\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    outputs = model(inputs)\n",
        "                    _, preds = torch.max(outputs, 1)\n",
        "                    \n",
        "                    loss = criterion_KD(outputs, labels, outputs_teacher, T, alpha)\n",
        "\n",
        "                    # backward + optimize only if in training phase\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "                # statistics\n",
        "                running_loss[phase] += loss.item() * inputs.shape[0]\n",
        "                running_acc[phase] += torch.sum(preds == labels.data)\n",
        "            \n",
        "            running_loss[phase] = running_loss[phase] / (len(dataloaders[phase]) * dataloaders[phase].batch_size)\n",
        "            running_acc[phase] = running_acc[phase].double() / (len(dataloaders[phase]) * dataloaders[phase].batch_size)\n",
        "\n",
        "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, running_loss[phase], running_acc[phase]))\n",
        "\n",
        "            # deep copy the model\n",
        "            if phase == 'val' and running_acc[phase] > best_acc:\n",
        "                best_acc = running_acc[phase]\n",
        "                best_model_wts = copy.deepcopy(model.state_dict())\n",
        "\n",
        "        writer.add_scalars(f'{model_name}/loss', {'train' : running_loss['train'], 'val' : running_loss['val']}, global_step)\n",
        "        writer.add_scalars(f'{model_name}/acc', {'train' : running_acc['train'], 'val' : running_acc['val']}, global_step)\n",
        "        global_step += 1\n",
        "\n",
        "        print()\n",
        "\n",
        "    print('Best val Acc: {:4f}'.format(best_acc))\n",
        "\n",
        "    # load best model weights\n",
        "    model.load_state_dict(best_model_wts)\n",
        "\n",
        "    torch.save(model.state_dict(), f'{model_name}.pt')\n",
        "    print('model saved')\n",
        "\n",
        "    writer.close()\n",
        "\n",
        "    return model"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yGebR4CsCXd_"
      },
      "source": [
        "## Student Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qnDfidNmCYBS",
        "outputId": "84f327d2-40e0-4cb1-f78c-d92a8a6358b0"
      },
      "source": [
        "optimizer = optim.Adam(student.parameters())\n",
        "best_student = trainer_KD('student', student, best_teacher, optimizer, num_epochs=30)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0/29\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2742: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.\n",
            "  \"reduction: 'mean' divides the total loss by both the batch size and the support size.\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train Loss: 0.9918 Acc: 0.4051\n",
            "val Loss: 0.8751 Acc: 0.4463\n",
            "\n",
            "Epoch 1/29\n",
            "----------\n",
            "train Loss: 0.8406 Acc: 0.4996\n",
            "val Loss: 0.7699 Acc: 0.5195\n",
            "\n",
            "Epoch 2/29\n",
            "----------\n",
            "train Loss: 0.7536 Acc: 0.5487\n",
            "val Loss: 0.6942 Acc: 0.5693\n",
            "\n",
            "Epoch 3/29\n",
            "----------\n",
            "train Loss: 0.6941 Acc: 0.5826\n",
            "val Loss: 0.6382 Acc: 0.5879\n",
            "\n",
            "Epoch 4/29\n",
            "----------\n",
            "train Loss: 0.6462 Acc: 0.6131\n",
            "val Loss: 0.5894 Acc: 0.6260\n",
            "\n",
            "Epoch 5/29\n",
            "----------\n",
            "train Loss: 0.6102 Acc: 0.6323\n",
            "val Loss: 0.5655 Acc: 0.6602\n",
            "\n",
            "Epoch 6/29\n",
            "----------\n",
            "train Loss: 0.5817 Acc: 0.6497\n",
            "val Loss: 0.5458 Acc: 0.6455\n",
            "\n",
            "Epoch 7/29\n",
            "----------\n",
            "train Loss: 0.5562 Acc: 0.6635\n",
            "val Loss: 0.5485 Acc: 0.6504\n",
            "\n",
            "Epoch 8/29\n",
            "----------\n",
            "train Loss: 0.5382 Acc: 0.6723\n",
            "val Loss: 0.5072 Acc: 0.6689\n",
            "\n",
            "Epoch 9/29\n",
            "----------\n",
            "train Loss: 0.5211 Acc: 0.6864\n",
            "val Loss: 0.5148 Acc: 0.6621\n",
            "\n",
            "Epoch 10/29\n",
            "----------\n",
            "train Loss: 0.5050 Acc: 0.6953\n",
            "val Loss: 0.4930 Acc: 0.6895\n",
            "\n",
            "Epoch 11/29\n",
            "----------\n",
            "train Loss: 0.4913 Acc: 0.7055\n",
            "val Loss: 0.4794 Acc: 0.6914\n",
            "\n",
            "Epoch 12/29\n",
            "----------\n",
            "train Loss: 0.4786 Acc: 0.7138\n",
            "val Loss: 0.4885 Acc: 0.6729\n",
            "\n",
            "Epoch 13/29\n",
            "----------\n",
            "train Loss: 0.4724 Acc: 0.7171\n",
            "val Loss: 0.4749 Acc: 0.6895\n",
            "\n",
            "Epoch 14/29\n",
            "----------\n",
            "train Loss: 0.4600 Acc: 0.7246\n",
            "val Loss: 0.4754 Acc: 0.6816\n",
            "\n",
            "Epoch 15/29\n",
            "----------\n",
            "train Loss: 0.4505 Acc: 0.7313\n",
            "val Loss: 0.4609 Acc: 0.7012\n",
            "\n",
            "Epoch 16/29\n",
            "----------\n",
            "train Loss: 0.4432 Acc: 0.7363\n",
            "val Loss: 0.4745 Acc: 0.6924\n",
            "\n",
            "Epoch 17/29\n",
            "----------\n",
            "train Loss: 0.4356 Acc: 0.7403\n",
            "val Loss: 0.4521 Acc: 0.7061\n",
            "\n",
            "Epoch 18/29\n",
            "----------\n",
            "train Loss: 0.4296 Acc: 0.7453\n",
            "val Loss: 0.4516 Acc: 0.6963\n",
            "\n",
            "Epoch 19/29\n",
            "----------\n",
            "train Loss: 0.4218 Acc: 0.7484\n",
            "val Loss: 0.4458 Acc: 0.7090\n",
            "\n",
            "Epoch 20/29\n",
            "----------\n",
            "train Loss: 0.4176 Acc: 0.7514\n",
            "val Loss: 0.4617 Acc: 0.6826\n",
            "\n",
            "Epoch 21/29\n",
            "----------\n",
            "train Loss: 0.4101 Acc: 0.7572\n",
            "val Loss: 0.4662 Acc: 0.6914\n",
            "\n",
            "Epoch 22/29\n",
            "----------\n",
            "train Loss: 0.4056 Acc: 0.7613\n",
            "val Loss: 0.4512 Acc: 0.7012\n",
            "\n",
            "Epoch 23/29\n",
            "----------\n",
            "train Loss: 0.3978 Acc: 0.7678\n",
            "val Loss: 0.4516 Acc: 0.7080\n",
            "\n",
            "Epoch 24/29\n",
            "----------\n",
            "train Loss: 0.3943 Acc: 0.7693\n",
            "val Loss: 0.4443 Acc: 0.7012\n",
            "\n",
            "Epoch 25/29\n",
            "----------\n",
            "train Loss: 0.3888 Acc: 0.7732\n",
            "val Loss: 0.4603 Acc: 0.7012\n",
            "\n",
            "Epoch 26/29\n",
            "----------\n",
            "train Loss: 0.3883 Acc: 0.7744\n",
            "val Loss: 0.4469 Acc: 0.7031\n",
            "\n",
            "Epoch 27/29\n",
            "----------\n",
            "train Loss: 0.3825 Acc: 0.7773\n",
            "val Loss: 0.4850 Acc: 0.6797\n",
            "\n",
            "Epoch 28/29\n",
            "----------\n",
            "train Loss: 0.3781 Acc: 0.7810\n",
            "val Loss: 0.4536 Acc: 0.7002\n",
            "\n",
            "Epoch 29/29\n",
            "----------\n",
            "train Loss: 0.3756 Acc: 0.7822\n",
            "val Loss: 0.4507 Acc: 0.6992\n",
            "\n",
            "Best val Acc: 0.708984\n",
            "model saved\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0vMyeTjRAOt8"
      },
      "source": [
        "## Student Accuracy Check"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bI_G0CNwFxFY",
        "outputId": "649c5250-4502-4054-d965-93c7bbf07b4b"
      },
      "source": [
        "checker(dataloaders['test'], best_student)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Got 7021 / 10000 correct (70.21)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UOCfUufGGtO-"
      },
      "source": [
        "## Comparision"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5y83hkdqG06b",
        "outputId": "40db2e3c-7faa-458f-9c63-a84f29657ded"
      },
      "source": [
        "print('[[Accuracy & #parameters & Inference TIme]]')\n",
        "print('[teacher]')\n",
        "checker(dataloaders['test'], best_teacher)\n",
        "print(sum(p.numel() for p in best_teacher.parameters() if p.requires_grad))\n",
        "print('[student_solo]')\n",
        "checker(dataloaders['test'], best_student_solo)\n",
        "print(sum(p.numel() for p in best_student_solo.parameters() if p.requires_grad))\n",
        "print('[student_kd]')\n",
        "checker(dataloaders['test'], best_student)\n",
        "print(sum(p.numel() for p in best_student.parameters() if p.requires_grad))"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[Accuracy & #parameters & Inference TIme]]\n",
            "[teacher]\n",
            "Got 7426 / 10000 correct (74.26)\n",
            "435550\n",
            "[student_solo]\n",
            "Got 7018 / 10000 correct (70.18)\n",
            "62430\n",
            "[student_kd]\n",
            "Got 7053 / 10000 correct (70.53)\n",
            "62430\n"
          ]
        }
      ]
    }
  ]
}