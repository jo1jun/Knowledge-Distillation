{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Knowledge_Distillation.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "mount_file_id": "1YcFV-da6HR3CNk_8n9KUbA_ieGm75iEa",
      "authorship_tag": "ABX9TyPAk3oi/owL7LIAPgxl5TWp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "a22f6ef9d0a647edb19df5f26391888f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_a19e76f55cf54fbc9ec5f53043265ab1",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_a1f7afcea7a645dda65588bc50e4b1be",
              "IPY_MODEL_4b9b91c7153c4b619b6f16a6ec44babd",
              "IPY_MODEL_9c1a6b0c45fa4539a64b0428b50b1d82"
            ]
          }
        },
        "a19e76f55cf54fbc9ec5f53043265ab1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a1f7afcea7a645dda65588bc50e4b1be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_1699f4618064458aa6e9f6f6c87d2bf5",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6698931a60224ffdbd7539eb06947b38"
          }
        },
        "4b9b91c7153c4b619b6f16a6ec44babd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_216215a3240343d786e49a212652c11c",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 170498071,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 170498071,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_eddae82019fa4256a4d99c991410b8b0"
          }
        },
        "9c1a6b0c45fa4539a64b0428b50b1d82": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_50511837b3de46608b4dff65d8ef76ac",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 170499072/? [00:05&lt;00:00, 31882895.83it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a9ee873954a3474497a37cd9f1d66129"
          }
        },
        "1699f4618064458aa6e9f6f6c87d2bf5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6698931a60224ffdbd7539eb06947b38": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "216215a3240343d786e49a212652c11c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "eddae82019fa4256a4d99c991410b8b0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "50511837b3de46608b4dff65d8ef76ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a9ee873954a3474497a37cd9f1d66129": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jo1jun/Knowledge-Distillation/blob/main/Knowledge_Distillation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AoAg2WbV5hP5"
      },
      "source": [
        "# Import"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OdgCXuhb5gm9"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import sampler\n",
        "\n",
        "import torchvision.datasets as dset\n",
        "import torchvision.transforms as T\n",
        "\n",
        "import numpy as np\n",
        "import copy\n",
        "\n",
        "# tensorboard writer\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FWY4iuIO6Dfc"
      },
      "source": [
        "# Classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WjefvTSj5loj"
      },
      "source": [
        "## CIFAR10 Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119,
          "referenced_widgets": [
            "a22f6ef9d0a647edb19df5f26391888f",
            "a19e76f55cf54fbc9ec5f53043265ab1",
            "a1f7afcea7a645dda65588bc50e4b1be",
            "4b9b91c7153c4b619b6f16a6ec44babd",
            "9c1a6b0c45fa4539a64b0428b50b1d82",
            "1699f4618064458aa6e9f6f6c87d2bf5",
            "6698931a60224ffdbd7539eb06947b38",
            "216215a3240343d786e49a212652c11c",
            "eddae82019fa4256a4d99c991410b8b0",
            "50511837b3de46608b4dff65d8ef76ac",
            "a9ee873954a3474497a37cd9f1d66129"
          ]
        },
        "id": "p2mPtZzy5pFZ",
        "outputId": "d5fef8bb-9ce6-46e2-df42-d9388a11036c"
      },
      "source": [
        "NUM_TRAIN = 49000\n",
        "\n",
        "transform = T.Compose([\n",
        "                T.ToTensor(),\n",
        "                T.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
        "            ])\n",
        "\n",
        "dataloaders = {}\n",
        "\n",
        "cifar10_train = dset.CIFAR10('./datasets', train=True, download=True,\n",
        "                             transform=transform)\n",
        "dataloaders['train'] = DataLoader(cifar10_train, batch_size=64, \n",
        "                          sampler=sampler.SubsetRandomSampler(range(NUM_TRAIN)))\n",
        "\n",
        "cifar10_val = dset.CIFAR10('./datasets', train=True, download=True,\n",
        "                           transform=transform)\n",
        "dataloaders['val'] = DataLoader(cifar10_val, batch_size=64, \n",
        "                        sampler=sampler.SubsetRandomSampler(range(NUM_TRAIN, 50000)))\n",
        "\n",
        "cifar10_test = dset.CIFAR10('./datasets', train=False, download=True, \n",
        "                            transform=transform)\n",
        "dataloaders['test'] = DataLoader(cifar10_test, batch_size=64)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./datasets/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a22f6ef9d0a647edb19df5f26391888f",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/170498071 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./datasets/cifar-10-python.tar.gz to ./datasets\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vdcN8xvm8RjU"
      },
      "source": [
        "## Trainer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Vo3LJ708S7p"
      },
      "source": [
        "def trainer(model_name, model, criterion, optimizer, num_epochs):\n",
        "\n",
        "    model.to(device)\n",
        "    writer = SummaryWriter(f'runs/{model_name}')\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    global_step, best_acc = 0, 0.0\n",
        "    running_loss, running_acc = {}, {}\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
        "        print('-' * 10)\n",
        "\n",
        "        # Each epoch has a training and validation phase\n",
        "        for phase in ['train', 'val']:\n",
        "            if phase == 'train':\n",
        "                model.train()  # Set model to training mode\n",
        "            else:\n",
        "                model.eval()   # Set model to evaluate mode\n",
        "\n",
        "            running_loss[phase], running_acc[phase] = 0.0, 0\n",
        "\n",
        "            # Iterate over data.\n",
        "            for inputs, labels in dataloaders[phase]:\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                # zero the parameter gradients\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # forward\n",
        "                # track history if only in train\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    outputs = model(inputs)\n",
        "                    _, preds = torch.max(outputs, 1)\n",
        "                    loss = criterion(outputs, labels)\n",
        "\n",
        "                    # backward + optimize only if in training phase\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "                # statistics\n",
        "                running_loss[phase] += loss.item() * inputs.shape[0]\n",
        "                running_acc[phase] += torch.sum(preds == labels.data)\n",
        "            \n",
        "            running_loss[phase] = running_loss[phase] / (len(dataloaders[phase]) * dataloaders[phase].batch_size)\n",
        "            running_acc[phase] = running_acc[phase].double() / (len(dataloaders[phase]) * dataloaders[phase].batch_size)\n",
        "\n",
        "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, running_loss[phase], running_acc[phase]))\n",
        "\n",
        "            # deep copy the model\n",
        "            if phase == 'val' and running_acc[phase] > best_acc:\n",
        "                best_acc = running_acc[phase]\n",
        "                best_model_wts = copy.deepcopy(model.state_dict())\n",
        "\n",
        "        writer.add_scalars(f'{model_name}/loss', {'train' : running_loss['train'], 'val' : running_loss['val']}, global_step)\n",
        "        writer.add_scalars(f'{model_name}/acc', {'train' : running_acc['train'], 'val' : running_acc['val']}, global_step)\n",
        "        global_step += 1\n",
        "\n",
        "        print()\n",
        "\n",
        "    print('Best val Acc: {:4f}'.format(best_acc))\n",
        "\n",
        "    # load best model weights\n",
        "    model.load_state_dict(best_model_wts)\n",
        "\n",
        "    torch.save(model.state_dict(), f'{model_name}.pt')\n",
        "    print('model saved')\n",
        "\n",
        "    writer.close()\n",
        "\n",
        "    return model"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hzhd3M2P6FYE"
      },
      "source": [
        "## Teacher"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JOJpOKdL6Go0"
      },
      "source": [
        "class Teacher(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=2, padding=1)\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
        "        self.conv3 = nn.Conv2d(64, 128, kernel_size=5, padding=1)\n",
        "        self.conv4 = nn.Conv2d(128, 64, kernel_size=5, stride=2, padding=1)\n",
        "        self.conv5 = nn.Conv2d(64, 10, kernel_size=3, stride=2, padding=1)\n",
        "        self.batch1 = nn.BatchNorm2d(32)\n",
        "        self.batch2 = nn.BatchNorm2d(64)\n",
        "        self.batch3 = nn.BatchNorm2d(128)\n",
        "        self.batch4 = nn.BatchNorm2d(64)\n",
        "        self.batch5 = nn.BatchNorm2d(10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.batch1(self.conv1(x)))\n",
        "        x = F.dropout2d(F.relu(self.batch2(self.conv2(x))), 0.1)\n",
        "        x = F.dropout2d(F.relu(self.batch3(self.conv3(x))), 0.2)\n",
        "        x = F.dropout2d(F.relu(self.batch4(self.conv4(x))), 0.1)\n",
        "        x = F.relu(self.batch5(self.conv5(x)))\n",
        "        x = F.avg_pool2d(x, x.shape[-2:]).squeeze() # global average pooling\n",
        "        return x"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e6SEfMGj8pBE",
        "outputId": "89af0a28-6ec8-4d42-f3fd-a36b099786bf"
      },
      "source": [
        "teacher = Teacher()\n",
        "print(sum(p.numel() for p in teacher.parameters() if p.requires_grad))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "435550\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5qm4cDGnDhlD"
      },
      "source": [
        "## Criterion"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6oKi9l_fDjOT"
      },
      "source": [
        "criterion = nn.CrossEntropyLoss()"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dg-vEYSY82Ik"
      },
      "source": [
        "## Teacher Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MMfVuQX28uZ8",
        "outputId": "f0a6ecf4-27b7-42ba-d8e3-63fd4a33ceb7"
      },
      "source": [
        "optimizer = optim.Adam(teacher.parameters())\n",
        "best_teacher = trainer('teacher', teacher, criterion, optimizer, num_epochs=30)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0/29\n",
            "----------\n",
            "train Loss: 1.6182 Acc: 0.4573\n",
            "val Loss: 1.3466 Acc: 0.5449\n",
            "\n",
            "Epoch 1/29\n",
            "----------\n",
            "train Loss: 1.2668 Acc: 0.5859\n",
            "val Loss: 1.1362 Acc: 0.6123\n",
            "\n",
            "Epoch 2/29\n",
            "----------\n",
            "train Loss: 1.0962 Acc: 0.6390\n",
            "val Loss: 1.0016 Acc: 0.6533\n",
            "\n",
            "Epoch 3/29\n",
            "----------\n",
            "train Loss: 0.9812 Acc: 0.6755\n",
            "val Loss: 0.9048 Acc: 0.6836\n",
            "\n",
            "Epoch 4/29\n",
            "----------\n",
            "train Loss: 0.8835 Acc: 0.7101\n",
            "val Loss: 0.8689 Acc: 0.6885\n",
            "\n",
            "Epoch 5/29\n",
            "----------\n",
            "train Loss: 0.8061 Acc: 0.7339\n",
            "val Loss: 0.8258 Acc: 0.7002\n",
            "\n",
            "Epoch 6/29\n",
            "----------\n",
            "train Loss: 0.7386 Acc: 0.7592\n",
            "val Loss: 0.7893 Acc: 0.7158\n",
            "\n",
            "Epoch 7/29\n",
            "----------\n",
            "train Loss: 0.6830 Acc: 0.7755\n",
            "val Loss: 0.7725 Acc: 0.7158\n",
            "\n",
            "Epoch 8/29\n",
            "----------\n",
            "train Loss: 0.6362 Acc: 0.7919\n",
            "val Loss: 0.7975 Acc: 0.6895\n",
            "\n",
            "Epoch 9/29\n",
            "----------\n",
            "train Loss: 0.5899 Acc: 0.8063\n",
            "val Loss: 0.7555 Acc: 0.7266\n",
            "\n",
            "Epoch 10/29\n",
            "----------\n",
            "train Loss: 0.5460 Acc: 0.8214\n",
            "val Loss: 0.7672 Acc: 0.7285\n",
            "\n",
            "Epoch 11/29\n",
            "----------\n",
            "train Loss: 0.5046 Acc: 0.8349\n",
            "val Loss: 0.7523 Acc: 0.7246\n",
            "\n",
            "Epoch 12/29\n",
            "----------\n",
            "train Loss: 0.4771 Acc: 0.8438\n",
            "val Loss: 0.8064 Acc: 0.7002\n",
            "\n",
            "Epoch 13/29\n",
            "----------\n",
            "train Loss: 0.4410 Acc: 0.8568\n",
            "val Loss: 0.8095 Acc: 0.7324\n",
            "\n",
            "Epoch 14/29\n",
            "----------\n",
            "train Loss: 0.4073 Acc: 0.8688\n",
            "val Loss: 0.7616 Acc: 0.7227\n",
            "\n",
            "Epoch 15/29\n",
            "----------\n",
            "train Loss: 0.3851 Acc: 0.8768\n",
            "val Loss: 0.8091 Acc: 0.7246\n",
            "\n",
            "Epoch 16/29\n",
            "----------\n",
            "train Loss: 0.3640 Acc: 0.8813\n",
            "val Loss: 0.8105 Acc: 0.7012\n",
            "\n",
            "Epoch 17/29\n",
            "----------\n",
            "train Loss: 0.3381 Acc: 0.8921\n",
            "val Loss: 0.8324 Acc: 0.7139\n",
            "\n",
            "Epoch 18/29\n",
            "----------\n",
            "train Loss: 0.3198 Acc: 0.8982\n",
            "val Loss: 0.8327 Acc: 0.7236\n",
            "\n",
            "Epoch 19/29\n",
            "----------\n",
            "train Loss: 0.3048 Acc: 0.9013\n",
            "val Loss: 0.9171 Acc: 0.7109\n",
            "\n",
            "Epoch 20/29\n",
            "----------\n",
            "train Loss: 0.2908 Acc: 0.9071\n",
            "val Loss: 0.9013 Acc: 0.6982\n",
            "\n",
            "Epoch 21/29\n",
            "----------\n",
            "train Loss: 0.2801 Acc: 0.9089\n",
            "val Loss: 0.8883 Acc: 0.7041\n",
            "\n",
            "Epoch 22/29\n",
            "----------\n",
            "train Loss: 0.2601 Acc: 0.9169\n",
            "val Loss: 0.9124 Acc: 0.7139\n",
            "\n",
            "Epoch 23/29\n",
            "----------\n",
            "train Loss: 0.2498 Acc: 0.9197\n",
            "val Loss: 0.8616 Acc: 0.7168\n",
            "\n",
            "Epoch 24/29\n",
            "----------\n",
            "train Loss: 0.2463 Acc: 0.9217\n",
            "val Loss: 0.8934 Acc: 0.7158\n",
            "\n",
            "Epoch 25/29\n",
            "----------\n",
            "train Loss: 0.2352 Acc: 0.9236\n",
            "val Loss: 0.8540 Acc: 0.7168\n",
            "\n",
            "Epoch 26/29\n",
            "----------\n",
            "train Loss: 0.2296 Acc: 0.9248\n",
            "val Loss: 0.8660 Acc: 0.7158\n",
            "\n",
            "Epoch 27/29\n",
            "----------\n",
            "train Loss: 0.2208 Acc: 0.9277\n",
            "val Loss: 0.9147 Acc: 0.6934\n",
            "\n",
            "Epoch 28/29\n",
            "----------\n",
            "train Loss: 0.2163 Acc: 0.9293\n",
            "val Loss: 0.9627 Acc: 0.7090\n",
            "\n",
            "Epoch 29/29\n",
            "----------\n",
            "train Loss: 0.2057 Acc: 0.9312\n",
            "val Loss: 0.9343 Acc: 0.7021\n",
            "\n",
            "Best val Acc: 0.732422\n",
            "model saved\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x_t--f4b9rIQ"
      },
      "source": [
        "## Checker"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SUge9itC9t_8"
      },
      "source": [
        "import time\n",
        "\n",
        "def checker(loader, model):\n",
        "    num_correct = 0\n",
        "    num_samples = 0\n",
        "    model.eval()\n",
        "    times = []\n",
        "    with torch.no_grad():\n",
        "        for x, y in loader:\n",
        "            x = x.to(device=device)\n",
        "            y = y.to(device=device)\n",
        "\n",
        "            start_time = time.time()\n",
        "\n",
        "            scores = model(x)\n",
        "\n",
        "            times.append(time.time() - start_time)\n",
        "\n",
        "            _, preds = scores.max(1)\n",
        "            num_correct += (preds == y).sum()\n",
        "            num_samples += preds.size(0)\n",
        "        acc = float(num_correct) / num_samples\n",
        "        print('Got %d / %d correct (%.2f)' % (num_correct, num_samples, 100 * acc))\n",
        "        print(\"Average Inference Time : \", np.mean(times))\n",
        "\n",
        "    return acc"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fEiqIHZ-_Uqo"
      },
      "source": [
        "## Teacher Accuracy Check"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vz-MC7Qr99-s",
        "outputId": "8121a6e6-5e46-458d-f33d-06ba50d79c70"
      },
      "source": [
        "checker(dataloaders['test'], best_teacher)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Got 7380 / 10000 correct (73.80)\n",
            "Average Inference Time :  0.0010606878122706323\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.738"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yOJZKKDs-cxY"
      },
      "source": [
        "## Student_Solo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CwYZEDn6-ipy"
      },
      "source": [
        "class Student_Solo(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=2, padding=1)\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
        "        self.conv3 = nn.Conv2d(64, 64, kernel_size=3, padding=1)\n",
        "        self.conv4 = nn.Conv2d(64, 10, kernel_size=3, stride=2, padding=1)\n",
        "        self.batch1 = nn.BatchNorm2d(32)\n",
        "        self.batch2 = nn.BatchNorm2d(64)\n",
        "        self.batch3 = nn.BatchNorm2d(64)\n",
        "        self.batch4 = nn.BatchNorm2d(10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.batch1(self.conv1(x)))\n",
        "        x = F.dropout2d(F.relu(self.batch2(self.conv2(x))), 0.1)\n",
        "        x = F.dropout2d(F.relu(self.batch3(self.conv3(x))), 0.1)\n",
        "        x = F.relu(self.batch4(self.conv4(x)))\n",
        "        x = F.avg_pool2d(x, x.shape[-2:]).squeeze() # global average pooling\n",
        "        return x"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "36tE-71__FrA",
        "outputId": "55e49e7a-6a66-4ee9-eac5-fab18899bb74"
      },
      "source": [
        "student_solo = Student_Solo()\n",
        "print(sum(p.numel() for p in student_solo.parameters() if p.requires_grad))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "62430\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p3XA1BXW_ARh"
      },
      "source": [
        "## Student_Solo Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FJPddHyB_COB",
        "outputId": "b3d5e618-3242-4c3e-b0eb-32b0f23ed36a"
      },
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(student_solo.parameters())\n",
        "best_student_solo = trainer('student_solo', student_solo, criterion, optimizer, num_epochs=30)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0/29\n",
            "----------\n",
            "train Loss: 1.7786 Acc: 0.4056\n",
            "val Loss: 1.5744 Acc: 0.4609\n",
            "\n",
            "Epoch 1/29\n",
            "----------\n",
            "train Loss: 1.5143 Acc: 0.5002\n",
            "val Loss: 1.3907 Acc: 0.5215\n",
            "\n",
            "Epoch 2/29\n",
            "----------\n",
            "train Loss: 1.3628 Acc: 0.5486\n",
            "val Loss: 1.2562 Acc: 0.5811\n",
            "\n",
            "Epoch 3/29\n",
            "----------\n",
            "train Loss: 1.2554 Acc: 0.5843\n",
            "val Loss: 1.1718 Acc: 0.5928\n",
            "\n",
            "Epoch 4/29\n",
            "----------\n",
            "train Loss: 1.1774 Acc: 0.6103\n",
            "val Loss: 1.1007 Acc: 0.6172\n",
            "\n",
            "Epoch 5/29\n",
            "----------\n",
            "train Loss: 1.1144 Acc: 0.6301\n",
            "val Loss: 1.0532 Acc: 0.6299\n",
            "\n",
            "Epoch 6/29\n",
            "----------\n",
            "train Loss: 1.0621 Acc: 0.6485\n",
            "val Loss: 1.0135 Acc: 0.6445\n",
            "\n",
            "Epoch 7/29\n",
            "----------\n",
            "train Loss: 1.0212 Acc: 0.6613\n",
            "val Loss: 0.9890 Acc: 0.6455\n",
            "\n",
            "Epoch 8/29\n",
            "----------\n",
            "train Loss: 0.9867 Acc: 0.6716\n",
            "val Loss: 0.9688 Acc: 0.6523\n",
            "\n",
            "Epoch 9/29\n",
            "----------\n",
            "train Loss: 0.9522 Acc: 0.6832\n",
            "val Loss: 0.9625 Acc: 0.6582\n",
            "\n",
            "Epoch 10/29\n",
            "----------\n",
            "train Loss: 0.9257 Acc: 0.6918\n",
            "val Loss: 0.9363 Acc: 0.6611\n",
            "\n",
            "Epoch 11/29\n",
            "----------\n",
            "train Loss: 0.9007 Acc: 0.6985\n",
            "val Loss: 0.9564 Acc: 0.6533\n",
            "\n",
            "Epoch 12/29\n",
            "----------\n",
            "train Loss: 0.8795 Acc: 0.7063\n",
            "val Loss: 0.9052 Acc: 0.6641\n",
            "\n",
            "Epoch 13/29\n",
            "----------\n",
            "train Loss: 0.8571 Acc: 0.7145\n",
            "val Loss: 0.8810 Acc: 0.6904\n",
            "\n",
            "Epoch 14/29\n",
            "----------\n",
            "train Loss: 0.8378 Acc: 0.7172\n",
            "val Loss: 0.8685 Acc: 0.6709\n",
            "\n",
            "Epoch 15/29\n",
            "----------\n",
            "train Loss: 0.8211 Acc: 0.7239\n",
            "val Loss: 0.8754 Acc: 0.6816\n",
            "\n",
            "Epoch 16/29\n",
            "----------\n",
            "train Loss: 0.7997 Acc: 0.7333\n",
            "val Loss: 0.8605 Acc: 0.6729\n",
            "\n",
            "Epoch 17/29\n",
            "----------\n",
            "train Loss: 0.7883 Acc: 0.7355\n",
            "val Loss: 0.8353 Acc: 0.6943\n",
            "\n",
            "Epoch 18/29\n",
            "----------\n",
            "train Loss: 0.7696 Acc: 0.7415\n",
            "val Loss: 0.8351 Acc: 0.6855\n",
            "\n",
            "Epoch 19/29\n",
            "----------\n",
            "train Loss: 0.7603 Acc: 0.7453\n",
            "val Loss: 0.8269 Acc: 0.6895\n",
            "\n",
            "Epoch 20/29\n",
            "----------\n",
            "train Loss: 0.7450 Acc: 0.7497\n",
            "val Loss: 0.8273 Acc: 0.6914\n",
            "\n",
            "Epoch 21/29\n",
            "----------\n",
            "train Loss: 0.7344 Acc: 0.7529\n",
            "val Loss: 0.8624 Acc: 0.6797\n",
            "\n",
            "Epoch 22/29\n",
            "----------\n",
            "train Loss: 0.7202 Acc: 0.7599\n",
            "val Loss: 0.8234 Acc: 0.6992\n",
            "\n",
            "Epoch 23/29\n",
            "----------\n",
            "train Loss: 0.7099 Acc: 0.7641\n",
            "val Loss: 0.8431 Acc: 0.6895\n",
            "\n",
            "Epoch 24/29\n",
            "----------\n",
            "train Loss: 0.7014 Acc: 0.7654\n",
            "val Loss: 0.8207 Acc: 0.6914\n",
            "\n",
            "Epoch 25/29\n",
            "----------\n",
            "train Loss: 0.6900 Acc: 0.7676\n",
            "val Loss: 0.8599 Acc: 0.6777\n",
            "\n",
            "Epoch 26/29\n",
            "----------\n",
            "train Loss: 0.6837 Acc: 0.7719\n",
            "val Loss: 0.8203 Acc: 0.7012\n",
            "\n",
            "Epoch 27/29\n",
            "----------\n",
            "train Loss: 0.6711 Acc: 0.7747\n",
            "val Loss: 0.8241 Acc: 0.6982\n",
            "\n",
            "Epoch 28/29\n",
            "----------\n",
            "train Loss: 0.6649 Acc: 0.7780\n",
            "val Loss: 0.8074 Acc: 0.6982\n",
            "\n",
            "Epoch 29/29\n",
            "----------\n",
            "train Loss: 0.6559 Acc: 0.7775\n",
            "val Loss: 0.8207 Acc: 0.6953\n",
            "\n",
            "Best val Acc: 0.701172\n",
            "model saved\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KTo7Qfni_YrY"
      },
      "source": [
        "## Student_Solo Accuracy Check"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "snZil1Zr_a9Z",
        "outputId": "e76adbe0-0e5f-42e9-cdff-48382b3a95ac"
      },
      "source": [
        "checker(dataloaders['test'], best_student_solo)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Got 6961 / 10000 correct (69.61)\n",
            "Average Inference Time :  0.0008471543621865048\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6961"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v9KYLLy-_dQB"
      },
      "source": [
        "## Student"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UPu-MJZ9AErk",
        "outputId": "2c959cf6-b234-48ff-e9ac-e08661bfa053"
      },
      "source": [
        "student = Student_Solo() # same architecture with student_solo\n",
        "print(sum(p.numel() for p in student_solo.parameters() if p.requires_grad))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "62430\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-6M6KccJDdZO"
      },
      "source": [
        "## Criterion (+ Distillation loss)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HJ61xe3cDgGT"
      },
      "source": [
        "def criterion_KD(outputs, labels, teacher_outputs, T, alpha):\n",
        "\n",
        "    KD_loss = nn.KLDivLoss()(F.log_softmax(outputs/T, dim=1), F.softmax(teacher_outputs/T, dim=1)) * (alpha * T * T) + \\\n",
        "              F.cross_entropy(outputs, labels) * (1. - alpha)\n",
        "\n",
        "    return KD_loss"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UDhpnZOSCOgB"
      },
      "source": [
        "## Trainer (+Distillation loss)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jvc24qWRCU2g"
      },
      "source": [
        "def trainer_KD(model_name, model, teacher, optimizer, num_epochs, T, alpha):\n",
        "\n",
        "    model.to(device)\n",
        "    teacher.to(device)\n",
        "    teacher.eval()\n",
        "    writer = SummaryWriter(f'runs/{model_name}')\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    global_step, best_acc = 0, 0.0\n",
        "    running_loss, running_acc = {}, {}\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
        "        print('-' * 10)\n",
        "\n",
        "        # Each epoch has a training and validation phase\n",
        "        for phase in ['train', 'val']:\n",
        "            if phase == 'train':\n",
        "                model.train()  # Set model to training mode\n",
        "            else:\n",
        "                model.eval()   # Set model to evaluate mode\n",
        "\n",
        "            running_loss[phase], running_acc[phase] = 0.0, 0\n",
        "\n",
        "            # Iterate over data.\n",
        "            for inputs, labels in dataloaders[phase]:\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                # zero the parameter gradients\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "\n",
        "                with torch.no_grad():\n",
        "                  outputs_teacher = teacher(inputs)\n",
        "\n",
        "                # forward\n",
        "                # track history if only in train\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    outputs = model(inputs)\n",
        "                    _, preds = torch.max(outputs, 1)\n",
        "                    \n",
        "                    loss = criterion_KD(outputs, labels, outputs_teacher, T, alpha)\n",
        "\n",
        "                    # backward + optimize only if in training phase\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "                # statistics\n",
        "                running_loss[phase] += loss.item() * inputs.shape[0]\n",
        "                running_acc[phase] += torch.sum(preds == labels.data)\n",
        "            \n",
        "            running_loss[phase] = running_loss[phase] / (len(dataloaders[phase]) * dataloaders[phase].batch_size)\n",
        "            running_acc[phase] = running_acc[phase].double() / (len(dataloaders[phase]) * dataloaders[phase].batch_size)\n",
        "\n",
        "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, running_loss[phase], running_acc[phase]))\n",
        "\n",
        "            # deep copy the model\n",
        "            if phase == 'val' and running_acc[phase] > best_acc:\n",
        "                best_acc = running_acc[phase]\n",
        "                best_model_wts = copy.deepcopy(model.state_dict())\n",
        "\n",
        "        writer.add_scalars(f'{model_name}/loss', {'train' : running_loss['train'], 'val' : running_loss['val']}, global_step)\n",
        "        writer.add_scalars(f'{model_name}/acc', {'train' : running_acc['train'], 'val' : running_acc['val']}, global_step)\n",
        "        global_step += 1\n",
        "\n",
        "        print()\n",
        "\n",
        "    print('Best val Acc: {:4f}'.format(best_acc))\n",
        "\n",
        "    # load best model weights\n",
        "    model.load_state_dict(best_model_wts)\n",
        "\n",
        "    torch.save(model.state_dict(), f'{model_name}.pt')\n",
        "    print('model saved')\n",
        "\n",
        "    writer.close()\n",
        "\n",
        "    return model"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yGebR4CsCXd_"
      },
      "source": [
        "## Student Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qnDfidNmCYBS",
        "outputId": "fadb01fe-151f-4c35-e56c-c6d850b0c2a9"
      },
      "source": [
        "T = 10\n",
        "alpha = 0.8\n",
        "optimizer = optim.Adam(student.parameters())\n",
        "num_epochs = 30\n",
        "best_student = trainer_KD('student', student, best_teacher, optimizer, num_epochs, T, alpha)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0/29\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2742: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.\n",
            "  \"reduction: 'mean' divides the total loss by both the batch size and the support size.\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train Loss: 0.5666 Acc: 0.4118\n",
            "val Loss: 0.4933 Acc: 0.4502\n",
            "\n",
            "Epoch 1/29\n",
            "----------\n",
            "train Loss: 0.4718 Acc: 0.5076\n",
            "val Loss: 0.4222 Acc: 0.5410\n",
            "\n",
            "Epoch 2/29\n",
            "----------\n",
            "train Loss: 0.4167 Acc: 0.5554\n",
            "val Loss: 0.3788 Acc: 0.5625\n",
            "\n",
            "Epoch 3/29\n",
            "----------\n",
            "train Loss: 0.3778 Acc: 0.5916\n",
            "val Loss: 0.3414 Acc: 0.6113\n",
            "\n",
            "Epoch 4/29\n",
            "----------\n",
            "train Loss: 0.3494 Acc: 0.6187\n",
            "val Loss: 0.3202 Acc: 0.6162\n",
            "\n",
            "Epoch 5/29\n",
            "----------\n",
            "train Loss: 0.3280 Acc: 0.6393\n",
            "val Loss: 0.2966 Acc: 0.6377\n",
            "\n",
            "Epoch 6/29\n",
            "----------\n",
            "train Loss: 0.3108 Acc: 0.6590\n",
            "val Loss: 0.2867 Acc: 0.6318\n",
            "\n",
            "Epoch 7/29\n",
            "----------\n",
            "train Loss: 0.2980 Acc: 0.6736\n",
            "val Loss: 0.2829 Acc: 0.6602\n",
            "\n",
            "Epoch 8/29\n",
            "----------\n",
            "train Loss: 0.2874 Acc: 0.6822\n",
            "val Loss: 0.2719 Acc: 0.6611\n",
            "\n",
            "Epoch 9/29\n",
            "----------\n",
            "train Loss: 0.2800 Acc: 0.6932\n",
            "val Loss: 0.2723 Acc: 0.6709\n",
            "\n",
            "Epoch 10/29\n",
            "----------\n",
            "train Loss: 0.2725 Acc: 0.7025\n",
            "val Loss: 0.2610 Acc: 0.6699\n",
            "\n",
            "Epoch 11/29\n",
            "----------\n",
            "train Loss: 0.2657 Acc: 0.7106\n",
            "val Loss: 0.2549 Acc: 0.6777\n",
            "\n",
            "Epoch 12/29\n",
            "----------\n",
            "train Loss: 0.2604 Acc: 0.7180\n",
            "val Loss: 0.2555 Acc: 0.6738\n",
            "\n",
            "Epoch 13/29\n",
            "----------\n",
            "train Loss: 0.2552 Acc: 0.7242\n",
            "val Loss: 0.2567 Acc: 0.6875\n",
            "\n",
            "Epoch 14/29\n",
            "----------\n",
            "train Loss: 0.2508 Acc: 0.7298\n",
            "val Loss: 0.2565 Acc: 0.6855\n",
            "\n",
            "Epoch 15/29\n",
            "----------\n",
            "train Loss: 0.2461 Acc: 0.7358\n",
            "val Loss: 0.2414 Acc: 0.7021\n",
            "\n",
            "Epoch 16/29\n",
            "----------\n",
            "train Loss: 0.2432 Acc: 0.7398\n",
            "val Loss: 0.2556 Acc: 0.7002\n",
            "\n",
            "Epoch 17/29\n",
            "----------\n",
            "train Loss: 0.2394 Acc: 0.7464\n",
            "val Loss: 0.2481 Acc: 0.6914\n",
            "\n",
            "Epoch 18/29\n",
            "----------\n",
            "train Loss: 0.2364 Acc: 0.7508\n",
            "val Loss: 0.2453 Acc: 0.6973\n",
            "\n",
            "Epoch 19/29\n",
            "----------\n",
            "train Loss: 0.2337 Acc: 0.7548\n",
            "val Loss: 0.2539 Acc: 0.6846\n",
            "\n",
            "Epoch 20/29\n",
            "----------\n",
            "train Loss: 0.2323 Acc: 0.7574\n",
            "val Loss: 0.2416 Acc: 0.7100\n",
            "\n",
            "Epoch 21/29\n",
            "----------\n",
            "train Loss: 0.2287 Acc: 0.7635\n",
            "val Loss: 0.2444 Acc: 0.6846\n",
            "\n",
            "Epoch 22/29\n",
            "----------\n",
            "train Loss: 0.2277 Acc: 0.7657\n",
            "val Loss: 0.2433 Acc: 0.7002\n",
            "\n",
            "Epoch 23/29\n",
            "----------\n",
            "train Loss: 0.2249 Acc: 0.7665\n",
            "val Loss: 0.2404 Acc: 0.6953\n",
            "\n",
            "Epoch 24/29\n",
            "----------\n",
            "train Loss: 0.2224 Acc: 0.7724\n",
            "val Loss: 0.2451 Acc: 0.7021\n",
            "\n",
            "Epoch 25/29\n",
            "----------\n",
            "train Loss: 0.2204 Acc: 0.7751\n",
            "val Loss: 0.2457 Acc: 0.6973\n",
            "\n",
            "Epoch 26/29\n",
            "----------\n",
            "train Loss: 0.2192 Acc: 0.7783\n",
            "val Loss: 0.2374 Acc: 0.7051\n",
            "\n",
            "Epoch 27/29\n",
            "----------\n",
            "train Loss: 0.2180 Acc: 0.7808\n",
            "val Loss: 0.2377 Acc: 0.7002\n",
            "\n",
            "Epoch 28/29\n",
            "----------\n",
            "train Loss: 0.2165 Acc: 0.7809\n",
            "val Loss: 0.2410 Acc: 0.7021\n",
            "\n",
            "Epoch 29/29\n",
            "----------\n",
            "train Loss: 0.2153 Acc: 0.7837\n",
            "val Loss: 0.2455 Acc: 0.6885\n",
            "\n",
            "Best val Acc: 0.709961\n",
            "model saved\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0vMyeTjRAOt8"
      },
      "source": [
        "## Student Accuracy Check"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bI_G0CNwFxFY",
        "outputId": "b26dafe6-bc30-46eb-fb7d-14bf4f90e863"
      },
      "source": [
        "checker(dataloaders['test'], best_student)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Got 7200 / 10000 correct (72.00)\n",
            "Average Inference Time :  0.0008396206388048306\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.72"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UOCfUufGGtO-"
      },
      "source": [
        "## Comparision"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5y83hkdqG06b",
        "outputId": "dc506305-b7d9-4496-f9e0-ac44589e33ce"
      },
      "source": [
        "print('[[Accuracy & #parameters & Inference TIme]]')\n",
        "print('[teacher]')\n",
        "checker(dataloaders['test'], best_teacher)\n",
        "print(sum(p.numel() for p in best_teacher.parameters() if p.requires_grad))\n",
        "print('[student_solo]')\n",
        "checker(dataloaders['test'], best_student_solo)\n",
        "print(sum(p.numel() for p in best_student_solo.parameters() if p.requires_grad))\n",
        "print('[student_kd]')\n",
        "checker(dataloaders['test'], best_student)\n",
        "print(sum(p.numel() for p in best_student.parameters() if p.requires_grad))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[Accuracy & #parameters & Inference TIme]]\n",
            "[teacher]\n",
            "Got 7398 / 10000 correct (73.98)\n",
            "Average Inference Time :  0.0010553135234079543\n",
            "435550\n",
            "[student_solo]\n",
            "Got 6974 / 10000 correct (69.74)\n",
            "Average Inference Time :  0.0008367368370104747\n",
            "62430\n",
            "[student_kd]\n",
            "Got 7216 / 10000 correct (72.16)\n",
            "Average Inference Time :  0.0008491300473547286\n",
            "62430\n"
          ]
        }
      ]
    }
  ]
}
